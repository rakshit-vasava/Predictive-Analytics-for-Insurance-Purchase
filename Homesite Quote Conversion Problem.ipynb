{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Rakshit Vasava, Individual Assignment 3**"
      ],
      "metadata": {
        "id": "18BALuf6Ar9u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Gv9FnkG3Wpk",
        "outputId": "aeedc661-77ca-4a27-b66c-49465737cbd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n",
            "/gdrive\n"
          ]
        }
      ],
      "source": [
        "# To upload our datasets from our working directory we need to mount our drive contents to the colab environment.\n",
        "# For the code to do so you can search “mount” in code snippets or use the code given below.\n",
        "# Our entire drive contents are now mounted on colab at the location “/gdrive”.\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "#Change current working directory to gdrive\n",
        "%cd /gdrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWXVFKJe3ZSj",
        "outputId": "9ecb6de5-70b0-41f7-a05c-c002e27c601c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: vecstack in /usr/local/lib/python3.10/dist-packages (0.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from vecstack) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from vecstack) (1.11.3)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.10/dist-packages (from vecstack) (1.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->vecstack) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->vecstack) (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install vecstack"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qqigdY6E3ZPX"
      },
      "outputs": [],
      "source": [
        "from vecstack import stacking\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score #works\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "#from sklearn.ensemble import RandomForestClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.svm import SVC\n",
        "from collections import Counter #for Smote,\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wXvFoub3ZMN",
        "outputId": "b812cc44-a9e9-4f2d-fcef-560e1f24467e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(65000, 596)\n",
            "(173836, 596)\n",
            "       CoverageField11A  CoverageField11B  CoverageField1A  CoverageField1B  \\\n",
            "64995                 3                 5                9               15   \n",
            "64996                 5                 9               14               21   \n",
            "64997                 7                14                3                2   \n",
            "64998                 5                 9               15               22   \n",
            "64999                 4                 6                7               12   \n",
            "\n",
            "       CoverageField2A  CoverageField2B  CoverageField3A  CoverageField3B  \\\n",
            "64995                9               15                8               13   \n",
            "64996               14               21               13               20   \n",
            "64997                3                3                2                2   \n",
            "64998               15               22               13               21   \n",
            "64999                8               13                7               11   \n",
            "\n",
            "       CoverageField4A  CoverageField4B  ...  PropertyField38_N  \\\n",
            "64995                8               14  ...                  1   \n",
            "64996               13               21  ...                  1   \n",
            "64997                3                2  ...                  1   \n",
            "64998               14               21  ...                  1   \n",
            "64999                7               12  ...                  1   \n",
            "\n",
            "       PropertyField38_Y  GeographicField63_   GeographicField63_N  \\\n",
            "64995                  0                    0                    1   \n",
            "64996                  0                    0                    1   \n",
            "64997                  0                    0                    1   \n",
            "64998                  0                    0                    1   \n",
            "64999                  0                    0                    1   \n",
            "\n",
            "       GeographicField63_Y  GeographicField64_CA  GeographicField64_IL  \\\n",
            "64995                    0                     1                     0   \n",
            "64996                    0                     0                     0   \n",
            "64997                    0                     0                     0   \n",
            "64998                    0                     0                     0   \n",
            "64999                    0                     1                     0   \n",
            "\n",
            "       GeographicField64_NJ  GeographicField64_TX  QuoteConversion_Flag  \n",
            "64995                     0                     0                     0  \n",
            "64996                     0                     1                     0  \n",
            "64997                     1                     0                     0  \n",
            "64998                     1                     0                     0  \n",
            "64999                     0                     0                     0  \n",
            "\n",
            "[5 rows x 596 columns]\n",
            "        CoverageField11A  CoverageField11B  CoverageField1A  CoverageField1B  \\\n",
            "173831                14                23               13               21   \n",
            "173832                 7                13               10               17   \n",
            "173833                12                22                4                4   \n",
            "173834                 6                11                4                5   \n",
            "173835                 2                 2               16               23   \n",
            "\n",
            "        CoverageField2A  CoverageField2B  CoverageField3A  CoverageField3B  \\\n",
            "173831               13               21               18               23   \n",
            "173832               10               17                9               15   \n",
            "173833                4                5                4                4   \n",
            "173834                4                5                4                4   \n",
            "173835               16               23               21               24   \n",
            "\n",
            "        CoverageField4A  CoverageField4B  ...  PropertyField38_N  \\\n",
            "173831               13               20  ...                  0   \n",
            "173832                9               16  ...                  1   \n",
            "173833                4                4  ...                  1   \n",
            "173834                4                4  ...                  1   \n",
            "173835               15               22  ...                  1   \n",
            "\n",
            "        PropertyField38_Y  GeographicField63_   GeographicField63_N  \\\n",
            "173831                  1                    0                    1   \n",
            "173832                  0                    0                    1   \n",
            "173833                  0                    0                    1   \n",
            "173834                  0                    0                    1   \n",
            "173835                  0                    0                    1   \n",
            "\n",
            "        GeographicField63_Y  GeographicField64_CA  GeographicField64_IL  \\\n",
            "173831                    0                     0                     0   \n",
            "173832                    0                     0                     0   \n",
            "173833                    0                     0                     0   \n",
            "173834                    0                     0                     0   \n",
            "173835                    0                     0                     0   \n",
            "\n",
            "        GeographicField64_NJ  GeographicField64_TX  GeographicField64  \n",
            "173831                     0                     0                 NJ  \n",
            "173832                     0                     0                 CA  \n",
            "173833                     0                     0                 CA  \n",
            "173834                     0                     0                 TX  \n",
            "173835                     0                     0                 NJ  \n",
            "\n",
            "[5 rows x 596 columns]\n"
          ]
        }
      ],
      "source": [
        "trainfile = r'/gdrive/My Drive/Colab Notebooks/RevisedHomesiteTrain1.csv'\n",
        "train_data = pd.read_csv(trainfile)\n",
        "\n",
        "testfile = r'/gdrive/My Drive/Colab Notebooks/RevisedHomesiteTest1.csv'\n",
        "test_data = pd.read_csv(testfile)\n",
        "\n",
        "print(train_data.shape)\n",
        "print(test_data.shape)\n",
        "print(train_data.tail())\n",
        "print(test_data.tail())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHS_xLrD3ZIr",
        "outputId": "027bd7d5-2ddd-4cd8-d38d-8e038af863d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(65000, 595)\n",
            "(65000,)\n",
            "(173836, 595)\n",
            "       CoverageField11A  CoverageField11B  CoverageField1A  CoverageField1B  \\\n",
            "64995                 3                 5                9               15   \n",
            "64996                 5                 9               14               21   \n",
            "64997                 7                14                3                2   \n",
            "64998                 5                 9               15               22   \n",
            "64999                 4                 6                7               12   \n",
            "\n",
            "       CoverageField2A  CoverageField2B  CoverageField3A  CoverageField3B  \\\n",
            "64995                9               15                8               13   \n",
            "64996               14               21               13               20   \n",
            "64997                3                3                2                2   \n",
            "64998               15               22               13               21   \n",
            "64999                8               13                7               11   \n",
            "\n",
            "       CoverageField4A  CoverageField4B  ...  PropertyField37_Y  \\\n",
            "64995                8               14  ...                  0   \n",
            "64996               13               21  ...                  1   \n",
            "64997                3                2  ...                  1   \n",
            "64998               14               21  ...                  0   \n",
            "64999                7               12  ...                  1   \n",
            "\n",
            "       PropertyField38_N  PropertyField38_Y  GeographicField63_   \\\n",
            "64995                  1                  0                    0   \n",
            "64996                  1                  0                    0   \n",
            "64997                  1                  0                    0   \n",
            "64998                  1                  0                    0   \n",
            "64999                  1                  0                    0   \n",
            "\n",
            "       GeographicField63_N  GeographicField63_Y  GeographicField64_CA  \\\n",
            "64995                    1                    0                     1   \n",
            "64996                    1                    0                     0   \n",
            "64997                    1                    0                     0   \n",
            "64998                    1                    0                     0   \n",
            "64999                    1                    0                     1   \n",
            "\n",
            "       GeographicField64_IL  GeographicField64_NJ  GeographicField64_TX  \n",
            "64995                     0                     0                     0  \n",
            "64996                     0                     0                     1  \n",
            "64997                     0                     1                     0  \n",
            "64998                     0                     1                     0  \n",
            "64999                     0                     0                     0  \n",
            "\n",
            "[5 rows x 595 columns]\n",
            "0        0\n",
            "1        0\n",
            "2        0\n",
            "3        0\n",
            "4        0\n",
            "        ..\n",
            "64995    0\n",
            "64996    0\n",
            "64997    0\n",
            "64998    0\n",
            "64999    0\n",
            "Name: QuoteConversion_Flag, Length: 65000, dtype: int64\n",
            "        CoverageField11A  CoverageField11B  CoverageField1A  CoverageField1B  \\\n",
            "173831                14                23               13               21   \n",
            "173832                 7                13               10               17   \n",
            "173833                12                22                4                4   \n",
            "173834                 6                11                4                5   \n",
            "173835                 2                 2               16               23   \n",
            "\n",
            "        CoverageField2A  CoverageField2B  CoverageField3A  CoverageField3B  \\\n",
            "173831               13               21               18               23   \n",
            "173832               10               17                9               15   \n",
            "173833                4                5                4                4   \n",
            "173834                4                5                4                4   \n",
            "173835               16               23               21               24   \n",
            "\n",
            "        CoverageField4A  CoverageField4B  ...  PropertyField37_Y  \\\n",
            "173831               13               20  ...                  0   \n",
            "173832                9               16  ...                  0   \n",
            "173833                4                4  ...                  1   \n",
            "173834                4                4  ...                  1   \n",
            "173835               15               22  ...                  0   \n",
            "\n",
            "        PropertyField38_N  PropertyField38_Y  GeographicField63_   \\\n",
            "173831                  0                  1                    0   \n",
            "173832                  1                  0                    0   \n",
            "173833                  1                  0                    0   \n",
            "173834                  1                  0                    0   \n",
            "173835                  1                  0                    0   \n",
            "\n",
            "        GeographicField63_N  GeographicField63_Y  GeographicField64_CA  \\\n",
            "173831                    1                    0                     0   \n",
            "173832                    1                    0                     0   \n",
            "173833                    1                    0                     0   \n",
            "173834                    1                    0                     0   \n",
            "173835                    1                    0                     0   \n",
            "\n",
            "        GeographicField64_IL  GeographicField64_NJ  GeographicField64_TX  \n",
            "173831                     0                     0                     0  \n",
            "173832                     0                     0                     0  \n",
            "173833                     0                     0                     0  \n",
            "173834                     0                     0                     0  \n",
            "173835                     0                     0                     0  \n",
            "\n",
            "[5 rows x 595 columns]\n"
          ]
        }
      ],
      "source": [
        "#Organize Train data and Test data\n",
        "X_train = train_data.iloc[:, :-1].copy()\n",
        "Y_train = train_data[\"QuoteConversion_Flag\"]\n",
        "\n",
        "X_test = test_data.iloc[:, :-1].copy()\n",
        "\n",
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(X_train.tail())\n",
        "print(Y_train)\n",
        "print(X_test.tail())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJc44luN3ZFy"
      },
      "outputs": [],
      "source": [
        "#CONSTRUCT DEFAULT DECISION TREE AND OBTAIN RESPECTIVE ACCURACY\n",
        "clf = DecisionTreeClassifier()\n",
        "clf.fit(X_train,Y_train)\n",
        "clf_predict=clf.predict(X_test)\n",
        "# print(\"accuracy Score (training) for Decision Tree:{0:6f}\".format(clf.score(X_test1,y_test)))\n",
        "# print(\"Confusion Matrix for Decision Tree\")\n",
        "# print(confusion_matrix(y_test,clf_predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2-wHFHj3ZCV",
        "outputId": "ebf8ee79-4fe2-4659-b290-4a6eaa34577c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'min_samples_split': 50, 'max_depth': 7}\n",
            "=== All AUC Scores ===\n",
            "[0.93940456 0.93388671 0.92640534 0.93591906 0.9308566  0.9374214\n",
            " 0.93840122 0.9281893  0.93865823 0.92668027]\n",
            "\n",
            "\n",
            "=== Mean AUC Score ===\n",
            "Mean AUC Score - Decision Tree:  0.9335822687537098\n"
          ]
        }
      ],
      "source": [
        "#Hyperparameter tuning done for decision tree classifier\n",
        "parameters={'min_samples_split' : range(10,100,10),'max_depth': range(1,20,2)}\n",
        "clf_random = RandomizedSearchCV(clf,parameters,n_iter=15)\n",
        "clf_random.fit(X_train, Y_train)\n",
        "grid_parm=clf_random.best_params_\n",
        "print(grid_parm)\n",
        "\n",
        "#Using the parameters obtained from HyperParameterTuning in the DecisionTreeClassifier\n",
        "clf = DecisionTreeClassifier(**grid_parm)\n",
        "clf.fit(X_train,Y_train)\n",
        "clf_predict = clf.predict(X_test)\n",
        "\n",
        "#Obtain accuracy ,confusion matrix,classification report and AUC values for the result above.\n",
        "# print(\"accuracy Score (training) after hypertuning for Decision Tree:{0:6f}\".format(clf.score(X_test1,y_test)))\n",
        "# print(\"Confusion Matrix after hypertuning for Decision Tree\")\n",
        "# print(confusion_matrix(y_test,clf_predict))\n",
        "# print(\"=== Classification Report ===\")\n",
        "# print(classification_report(y_test,clf_predict))\n",
        "\n",
        "#get cross-validation report\n",
        "clf_cv_score = cross_val_score(clf, X_train, Y_train, cv=10, scoring=\"roc_auc\")\n",
        "print(\"=== All AUC Scores ===\")\n",
        "print(clf_cv_score)\n",
        "print('\\n')\n",
        "print(\"=== Mean AUC Score ===\")\n",
        "print(\"Mean AUC Score - Decision Tree: \",clf_cv_score.mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KivIyoeO3Y_b"
      },
      "outputs": [],
      "source": [
        "#Construct Random Forest Model\n",
        "\n",
        "rfc = RandomForestClassifier()\n",
        "rfc.fit(X_train, Y_train)\n",
        "rfc_predict=rfc.predict(X_test)\n",
        "# print(\"accuracy Score (training) for RandomForest:{0:6f}\".format(rfc.score(X_test1,y_test)))\n",
        "# print(\"Confusion Matrix for Random Forest:\")\n",
        "# print(confusion_matrix(y_test,rfc_predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JpNKZoy63Y5g"
      },
      "outputs": [],
      "source": [
        "#Construct MultiLayer Perceptron Model\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "mlp = MLPClassifier(max_iter=100)\n",
        "mlp.fit(X_train, Y_train)\n",
        "mlp_predict=mlp.predict(X_test)\n",
        "# print(\"accuracy Score (training) for MultiLayer Perceptron:{0:6f}\".format(mlp.score(X_test1,y_test)))\n",
        "# print(\"Confusion Matrix for MultiLayer Perceptron:\")\n",
        "# print(confusion_matrix(y_test,mlp_predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kUiDvVNm3Yza"
      },
      "outputs": [],
      "source": [
        "#Construct K-Nearest Neighbor Model\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "neigh = KNeighborsClassifier(n_neighbors=3)\n",
        "\n",
        "neigh.fit(X_train, Y_train)\n",
        "neigh_predict=neigh.predict(X_test)\n",
        "# print(\"accuracy Score (training) for KNeighborsClassifier:{0:6f}\".format(neigh.score(X_test1,y_test)))\n",
        "# print(\"Confusion Matrix for KNeighborsClassifier:\")\n",
        "# print(confusion_matrix(y_test,neigh_predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CeT3TlaG3Yto"
      },
      "outputs": [],
      "source": [
        "#Construct Linear Support Vector Machine Model\n",
        "from sklearn.svm import LinearSVC\n",
        "linsvm = LinearSVC(max_iter=300)\n",
        "linsvm.fit(X_train, Y_train)\n",
        "linsvm_predict=linsvm.predict(X_test)\n",
        "# print(\"accuracy Score (training) for Linear SVM Classifier:{0:6f}\".format(linsvm.score(X_test1,y_test)))\n",
        "# print(\"Confusion Matrix for Linear SVM Classifier:\")\n",
        "# print(confusion_matrix(y_test,linsvm_predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_aDYwLY3Yny",
        "outputId": "a46d56ee-f235-4b73-a5ec-7f4fd707a3bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'n_estimators': 20, 'learning_rate': 0.1}\n",
            "=== All AUC Scores ===\n",
            "[0.93884772 0.92937421 0.9293074  0.93389785 0.92874445 0.94154749\n",
            " 0.94628803 0.9207169  0.93271786 0.92644673]\n",
            "\n",
            "\n",
            "=== Mean AUC Score ===\n",
            "Mean AUC Score - Boosting:  0.9327888629821928\n"
          ]
        }
      ],
      "source": [
        "#Construct Gradient Boosting model\n",
        "\n",
        "search_grid={'n_estimators':[5,10,20],'learning_rate':[0.01,.1]}\n",
        "abc =GradientBoostingClassifier()\n",
        "abc.fit(X_train, Y_train)\n",
        "abc_predict=abc.predict(X_test)\n",
        "# print(\"accuracy Score (training) for Boosting:{0:6f}\".format(abc.score(X_test1,y_test)))\n",
        "# print(\"Confusion Matrix for boosting:\")\n",
        "# print(confusion_matrix(y_test,abc_predict))\n",
        "\n",
        "abc_random = RandomizedSearchCV(abc,search_grid,n_iter=15)\n",
        "abc_random.fit(X_train, Y_train)\n",
        "grid_parm_abc=abc_random.best_params_\n",
        "print(grid_parm_abc)\n",
        "abc= GradientBoostingClassifier(**grid_parm_abc)\n",
        "abc.fit(X_train,Y_train)\n",
        "abc_predict = abc.predict(X_test)\n",
        "# print(\"accuracy Score (training) after hypertuning for Boosting:{0:6f}\".format(abc.score(X_test1,y_test)))\n",
        "# print(\"Confusion Matrix after hypertuning for Boosting:\")\n",
        "# print(confusion_matrix(y_test,abc_predict))\n",
        "# print(\"=== Classification Report ===\")\n",
        "# print(classification_report(y_test,abc_predict))\n",
        "\n",
        "abc_cv_score = cross_val_score(abc, X_train, Y_train, cv=10, scoring=\"roc_auc\")\n",
        "print(\"=== All AUC Scores ===\")\n",
        "print(abc_cv_score)\n",
        "print('\\n')\n",
        "print(\"=== Mean AUC Score ===\")\n",
        "print(\"Mean AUC Score - Boosting: \",abc_cv_score.mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SMOTE**"
      ],
      "metadata": {
        "id": "9HrGcZIuAD1t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjPQXrpJ3YlK",
        "outputId": "f9b25dbc-50e2-4e3d-cb91-5285eec780d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "___________________________________________________________________\n",
            "SMOTE\n",
            "\n",
            "Original dataset shape Counter({0: 52738, 1: 12262})\n",
            "Resampled dataset shape Counter({0: 52738, 1: 26369})\n"
          ]
        }
      ],
      "source": [
        "print(\"___________________________________________________________________\\nSMOTE\\n\")\n",
        "print('Original dataset shape %s' % Counter(Y_train))\n",
        "sm = SMOTE(sampling_strategy=0.5)\n",
        "X_res, y_res = sm.fit_resample(X_train, Y_train)\n",
        "print('Resampled dataset shape %s' % Counter(y_res))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stacking**"
      ],
      "metadata": {
        "id": "SuSYVq1EAJEY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRMu_65T-Ht5",
        "outputId": "ca6bc762-93a5-4621-f49e-d8e36e826782"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "___________________________________________________________________________________________\n",
            "Ensemble Methods Predictions using GradientBoosting, RandomForest and Decision Tree Classifier\n",
            "\n",
            "task:         [classification]\n",
            "n_classes:    [2]\n",
            "metric:       [accuracy_score]\n",
            "mode:         [oof_pred_bag]\n",
            "n_models:     [5]\n",
            "\n",
            "model  0:     [KNeighborsClassifier]\n",
            "    fold  0:  [0.70314001]\n",
            "    fold  1:  [0.69727461]\n",
            "    fold  2:  [0.69909491]\n",
            "    fold  3:  [0.69559061]\n",
            "    ----\n",
            "    MEAN:     [0.69877504] + [0.00280834]\n",
            "    FULL:     [0.69877508]\n",
            "\n",
            "model  1:     [MLPClassifier]\n",
            "    fold  0:  [0.84623553]\n",
            "    fold  1:  [0.84709511]\n",
            "    fold  2:  [0.89523183]\n",
            "    fold  3:  [0.84167678]\n",
            "    ----\n",
            "    MEAN:     [0.85755981] + [0.02184720]\n",
            "    FULL:     [0.85756001]\n",
            "\n",
            "model  2:     [LinearSVC]\n",
            "    fold  0:  [0.67679628]\n",
            "    fold  1:  [0.68518987]\n",
            "    fold  2:  [0.58633766]\n",
            "    fold  3:  [0.58328277]\n",
            "    ----\n",
            "    MEAN:     [0.63290164] + [0.04819501]\n",
            "    FULL:     [0.63290227]\n",
            "\n",
            "model  3:     [RandomForestClassifier]\n",
            "    fold  0:  [0.92208121]\n",
            "    fold  1:  [0.92106993]\n",
            "    fold  2:  [0.92177782]\n",
            "    fold  3:  [0.92192557]\n",
            "    ----\n",
            "    MEAN:     [0.92171363] + [0.00038681]\n",
            "    FULL:     [0.92171363]\n",
            "\n",
            "model  4:     [DecisionTreeClassifier]\n",
            "    fold  0:  [0.89391718]\n",
            "    fold  1:  [0.89432169]\n",
            "    fold  2:  [0.89513071]\n",
            "    fold  3:  [0.89684466]\n",
            "    ----\n",
            "    MEAN:     [0.89505356] + [0.00112261]\n",
            "    FULL:     [0.89505354]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"___________________________________________________________________________________________\\nEnsemble Methods Predictions using GradientBoosting, RandomForest and Decision Tree Classifier\\n\")\n",
        "\n",
        "models = [ KNeighborsClassifier(), MLPClassifier(), LinearSVC(), RandomForestClassifier(), DecisionTreeClassifier() ]\n",
        "\n",
        "S_Train, S_Test = stacking(models,\n",
        "                           X_res, y_res, X_test,\n",
        "                           regression=False,\n",
        "\n",
        "                           mode='oof_pred_bag',\n",
        "\n",
        "                           needs_proba=False,\n",
        "\n",
        "                           save_dir=None,\n",
        "\n",
        "                           metric=accuracy_score,\n",
        "\n",
        "                           n_folds=4,\n",
        "\n",
        "                           stratified=True,\n",
        "\n",
        "                           shuffle=True,\n",
        "\n",
        "                           random_state=0,\n",
        "\n",
        "                           verbose=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQ_fysI1nnM-"
      },
      "outputs": [],
      "source": [
        "model = RandomForestClassifier()\n",
        "\n",
        "model = model.fit(S_Train, y_res)\n",
        "y_pred = model.predict(S_Test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bq0kwxu8JYEz",
        "outputId": "9a744c12-87ac-4117-c241-1c732d52d0b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 0 0 ... 1 0 0]\n"
          ]
        }
      ],
      "source": [
        "print(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXzDIKWT15nU",
        "outputId": "ffd2c1af-ce52-4a0f-fef7-bd0dde00e516"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(173836, 5)\n",
            "(173836, 1)\n",
            "   0  1  2  3  4\n",
            "0  0  0  0  0  0\n",
            "1  0  0  0  0  0\n",
            "2  1  0  0  0  0\n",
            "3  0  0  0  0  0\n",
            "4  0  0  0  0  0\n",
            "   0\n",
            "0  0\n",
            "1  0\n",
            "2  0\n",
            "3  0\n",
            "4  0\n"
          ]
        }
      ],
      "source": [
        "S_Test_df = pd.DataFrame(S_Test)\n",
        "y_pred_df = pd.DataFrame(y_pred)\n",
        "\n",
        "print(S_Test_df.shape)\n",
        "print(y_pred_df.shape)\n",
        "print(S_Test_df.head())\n",
        "print(y_pred_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQDSsafL9xcP"
      },
      "outputs": [],
      "source": [
        "model.predict_proba(S_Test)\n",
        "\n",
        "# '/gdrive/My Drive/Colab Notebooks/sample_submission.csv'\n",
        "# Export as CSV\n",
        "sub=pd.read_csv(\"/gdrive/My Drive/Colab Notebooks/sample_submission.csv\")\n",
        "output=pd.concat([sub[\"QuoteNumber\"],pd.DataFrame(y_pred,columns=[\"QuoteConversion_Flag\"])],axis=1)\n",
        "output.to_csv(\"/gdrive/My Drive/Colab Notebooks/CIS508_Assg3_Result.csv\",index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hyperparameter Tuning for Stacking**"
      ],
      "metadata": {
        "id": "hHEjU8iRATPk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AWW69H3lBev5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "763f4ba8-74c2-4d53-e132-a9bb3636c441"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
            "[CV] END ......................max_depth=30, n_estimators=70; total time=   1.0s\n",
            "[CV] END ......................max_depth=30, n_estimators=70; total time=   1.0s\n",
            "[CV] END ......................max_depth=30, n_estimators=70; total time=   1.0s\n",
            "[CV] END .....................max_depth=20, n_estimators=177; total time=   2.5s\n",
            "[CV] END .....................max_depth=20, n_estimators=177; total time=   1.7s\n",
            "[CV] END .....................max_depth=20, n_estimators=177; total time=   1.7s\n",
            "[CV] END ......................max_depth=40, n_estimators=96; total time=   0.9s\n",
            "[CV] END ......................max_depth=40, n_estimators=96; total time=   0.9s\n",
            "[CV] END ......................max_depth=40, n_estimators=96; total time=   1.0s\n",
            "[CV] END ...................max_depth=None, n_estimators=134; total time=   1.2s\n",
            "[CV] END ...................max_depth=None, n_estimators=134; total time=   1.3s\n",
            "[CV] END ...................max_depth=None, n_estimators=134; total time=   1.4s\n",
            "[CV] END ......................max_depth=20, n_estimators=89; total time=   1.3s\n",
            "[CV] END ......................max_depth=20, n_estimators=89; total time=   1.3s\n",
            "[CV] END ......................max_depth=20, n_estimators=89; total time=   1.3s\n",
            "[CV] END ...................max_depth=None, n_estimators=100; total time=   1.4s\n",
            "[CV] END ...................max_depth=None, n_estimators=100; total time=   1.4s\n",
            "[CV] END ...................max_depth=None, n_estimators=100; total time=   1.1s\n",
            "[CV] END ......................max_depth=40, n_estimators=52; total time=   0.5s\n",
            "[CV] END ......................max_depth=40, n_estimators=52; total time=   0.5s\n",
            "[CV] END ......................max_depth=40, n_estimators=52; total time=   0.5s\n",
            "[CV] END .....................max_depth=10, n_estimators=167; total time=   1.6s\n",
            "[CV] END .....................max_depth=10, n_estimators=167; total time=   1.6s\n",
            "[CV] END .....................max_depth=10, n_estimators=167; total time=   1.7s\n",
            "[CV] END .....................max_depth=20, n_estimators=189; total time=   1.8s\n",
            "[CV] END .....................max_depth=20, n_estimators=189; total time=   2.3s\n",
            "[CV] END .....................max_depth=20, n_estimators=189; total time=   2.8s\n",
            "[CV] END .....................max_depth=30, n_estimators=159; total time=   2.2s\n",
            "[CV] END .....................max_depth=30, n_estimators=159; total time=   1.8s\n",
            "[CV] END .....................max_depth=30, n_estimators=159; total time=   1.6s\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from vecstack import stacking\n",
        "from scipy.stats import randint\n",
        "\n",
        "# Define base models\n",
        "models = [\n",
        "    KNeighborsClassifier(),\n",
        "    MLPClassifier(),\n",
        "    LinearSVC(),\n",
        "    RandomForestClassifier(),\n",
        "    DecisionTreeClassifier()\n",
        "]\n",
        "\n",
        "# Fit each model and create predictions\n",
        "def create_base_predictions(models, X_train, X_test, y_train):\n",
        "    meta_X_train = []\n",
        "    meta_X_test = []\n",
        "    for model in models:\n",
        "        model.fit(X_train, y_train)\n",
        "        meta_X_train.append(model.predict(X_train))\n",
        "        meta_X_test.append(model.predict(X_test))\n",
        "    return np.column_stack(meta_X_train), np.column_stack(meta_X_test)\n",
        "\n",
        "# Assuming X_res, y_res, X_test are your training, validation, and testing sets respectively\n",
        "# Get predictions from base models\n",
        "S_train, S_test = create_base_predictions(models, X_res, X_test, y_res)\n",
        "\n",
        "# Define parameters for meta-classifier (Random Forest in this case)\n",
        "param_dist = {\n",
        "    'n_estimators': randint(50, 200),\n",
        "    'max_depth': [10, 20, 30, 40, None],\n",
        "    # Add other parameters for RandomForestClassifier as needed\n",
        "}\n",
        "\n",
        "# Instantiate Random Forest for meta-classifier\n",
        "meta_model = RandomForestClassifier()\n",
        "\n",
        "# Perform RandomizedSearchCV for meta-classifier\n",
        "random_search = RandomizedSearchCV(meta_model, param_distributions=param_dist, n_iter=10, cv=3, scoring='accuracy', verbose=2)\n",
        "random_search.fit(S_train, y_res)\n",
        "\n",
        "# Get best parameters and best estimator\n",
        "best_params = random_search.best_params_\n",
        "best_estimator = random_search.best_estimator_\n",
        "\n",
        "# Predict using the best estimator for the meta-classifier\n",
        "final_predictions = best_estimator.predict(S_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(final_predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "is1I6UJ_5ujh",
        "outputId": "486d6b7e-aea8-4f96-a2bf-56e849a9ac69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 1 ... 1 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sub=pd.read_csv(\"/gdrive/My Drive/Colab Notebooks/sample_submission.csv\")\n",
        "output=pd.concat([sub[\"QuoteNumber\"],pd.DataFrame(final_predictions,columns=[\"QuoteConversion_Flag\"])],axis=1)\n",
        "output.to_csv(\"/gdrive/My Drive/Colab Notebooks/CIS508_Assg3_Result_1.csv\",index=False)"
      ],
      "metadata": {
        "id": "29blOucYkAaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I5jbJQCE54I-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}